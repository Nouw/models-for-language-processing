{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nouw/models-for-language-processing/blob/master/M4LP_Assignment_2_(2024)_student_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zydk5m0FpaKT"
      },
      "source": [
        "## Assignment 2\n",
        "\n",
        "This is the complete Assignment 2. You are asked to train and test linear and logistic regression models and access lexical resources."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "~~Delete this text and write instead of it your:~~\n",
        "* ~~group number (same as the file name, for sanity chack)~~\n",
        "* ~~a list of group members names (NOT student IDs)~~\n",
        "* ~~who contributed to which exercises (you don't need to be very detailed)~~"
      ],
      "metadata": {
        "id": "8rvH77dcj-2Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ledaEclUpvzT"
      },
      "source": [
        "To start the assignment, import prerequisite packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRh6vltQpvTn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext as text\n",
        "import numpy as np\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import nltk,sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM9Qv40viw_l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import collections, itertools\n",
        "import more_itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKO1jxm3pv93"
      },
      "source": [
        "# 2.1 Import GloVe word embedding model\n",
        "\n",
        "GloVe contains _static_ word embeddings. This means that the vector is assigned to word types and does not vary in different contexts or for different word senses. Pretrained GloVe word embedding models exist in different sizes. For the purpose of the exercise, we will use the smallest GloVe vectors with 50 dimensions. First, let's download the vectors. This may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIkj-FlUpX9-"
      },
      "outputs": [],
      "source": [
        "glovedim=50\n",
        "#If you experience an issue downloading the vectors, try a different download source by uncommenting the following line:\n",
        "#text.vocab.GloVe.url[\"6B\"] = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\"\n",
        "vec = text.vocab.GloVe(name='6B', dim=glovedim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPoOZtlxqII4"
      },
      "source": [
        "How many words does it contain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JMWM-iTqHNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42080333-bb21-4ffc-c060-2e86aa371246"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#your code here\n",
        "len(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check if particular orthographic words have vectors in `vec`"
      ],
      "metadata": {
        "id": "6iaJetpi504A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check if \"cat\" has a GloVe vector, return a Boolean value\n",
        "#your code here"
      ],
      "metadata": {
        "id": "9OgJUGNDjAME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if \"cact\" has a GloVe vector, return a Boolean value\n",
        "#your code here"
      ],
      "metadata": {
        "id": "rStigiAbjJ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if \"cact\" has a GloVe vector, return a Boolean value\n",
        "#your code here"
      ],
      "metadata": {
        "id": "sWPUwXTayYHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkVR4dXbqOSY"
      },
      "source": [
        "What is the vector of _cat_?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-EQf6-dqN_A"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byR4o0uZuYU0"
      },
      "source": [
        "# 2.2 Linear regression: Concreteness prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MudXBEHPqZQR"
      },
      "source": [
        "Obtain concreteness ratings from the paper\n",
        "\n",
        "Brysbaert, M., Warriner, A., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. BEHAVIOR RESEARCH METHODS, 46 (3), 904â€“911. https://doi.org/10.3758/s13428-013-0403-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpty1jvvqZxR"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/ArtsEngine/concreteness/master/Concreteness_ratings_Brysbaert_et_al_BRM.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTWFbrn6q1gE"
      },
      "source": [
        "This is a tab-separated file with a header. Structured data like this can be conveniently read via DictReader class from csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJzFEjb1q6XK"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koGwR3hfrNR_"
      },
      "source": [
        "Using DictReader, create lists ```concreteness_words``` and ```concreteness_scores``` of words in the concreteness ratings file that have a GloVe vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwSaCcHBrhjf"
      },
      "outputs": [],
      "source": [
        "concreteness_words=[]\n",
        "concreteness_scores=[]\n",
        "with open(\"Concreteness_ratings_Brysbaert_et_al_BRM.txt\",'r') as concfile:\n",
        "  read_tsv = csv.DictReader(concfile, delimiter=\"\\t\")\n",
        "  # complete the code below"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many words ended up in your concreteness dataset?"
      ],
      "metadata": {
        "id": "0MQ7uWgvQxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(concreteness_words)"
      ],
      "metadata": {
        "id": "AUgfX_wrQszF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDKmvggQrq9X"
      },
      "source": [
        "Create train and test partitions of the concreteness data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCoOZ32trriI"
      },
      "outputs": [],
      "source": [
        "conc_words_train, conc_words_test, conc_scores_train, conc_scores_test = train_test_split(concreteness_words,concreteness_scores,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKo12DqNr57Z"
      },
      "source": [
        "Convert data to torch tensor format to use in a regression model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IExC7ts2r6WF"
      },
      "outputs": [],
      "source": [
        "#here we *stack* vectors for all words in a single torch tensor:\n",
        "vecs_train=torch.stack([vec[w] for w in conc_words_train])\n",
        "vecs_test=torch.stack([vec[w] for w in conc_words_test])\n",
        "#here we convert lists of scores into a tensor\n",
        "scores_train=torch.tensor(conc_scores_train)\n",
        "scores_test=torch.tensor(conc_scores_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA41kZdKsKgR"
      },
      "source": [
        "Now we can define linear regression model in pyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1QduXYcsOj3"
      },
      "outputs": [],
      "source": [
        "class Regression(torch.nn.Module):\n",
        "     def __init__(self, input_dim, output_dim):\n",
        "         super(Regression, self).__init__()\n",
        "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "     def forward(self, x):\n",
        "         outputs = self.linear(x)\n",
        "         return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGGf2CJksYPp"
      },
      "source": [
        "A specific linear regression model can have the input dimensionality of our word embeddings and 1-dimensional input (the concretenss score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfQIuGBqsXoG"
      },
      "outputs": [],
      "source": [
        "model = Regression(glovedim,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQcK2QCqsy4P"
      },
      "source": [
        "To train the model, we need a loss function and an optimiser:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJHqQcuaMcNL"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIuhn2FeNCph"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjjMEoVvtSc0"
      },
      "source": [
        "We can now train our linear regression model using gradient descent. Every 5 training steps, evaluate the model, printing out loss and accuracy for the training and test sets. Calculate the accuracy as the percentage of examples where the predicted score of the model differs from the correct score by less than 1. The training may take a minute or so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDQGZSxWsyPH"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "losses_test = []\n",
        "Iterations = []\n",
        "epochs=20\n",
        "tolerance = 1.0\n",
        "#after defining parameters, we train the model several times on the same data; each iteration is an epoch:\n",
        "for epoch in trange(epochs, desc='Training Epochs'):\n",
        "    x = vecs_train\n",
        "    scores = scores_train\n",
        "    optimizer.zero_grad()\n",
        "    #here we pass the word vectors from the training set, obtaining regression model's predicted outputs:\n",
        "    outputs = model(x)\n",
        "    loss = criterion(torch.squeeze(outputs), scores)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #Now, every 5 epochs we can evaluate how the model performs on the data\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        #we don't compute gradients as the model is only evaluated and not updated\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            #complete the code for evaluating the model here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SJ3qAwKfDov"
      },
      "source": [
        "What is the predicted concreteness score of the noun _abstractness_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z76FnkTpAeO3"
      },
      "outputs": [],
      "source": [
        "def predicted_concreteness(wd):\n",
        "  #complete the code here\n",
        "\n",
        "predicted_concreteness(\"abstractness\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIXDRq0yfL5m"
      },
      "source": [
        "What is the predicted concreteness score of the noun _dog_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu2jvBh5fAmq"
      },
      "outputs": [],
      "source": [
        "predicted_concreteness(\"dog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6CTQkPAviBj"
      },
      "source": [
        "# 2.3. Create a dataset of WordNet supersenses for words that have GloVe vectors.\n",
        "\n",
        "First, download the WordNet database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_TbA4Pfv9v5",
        "outputId": "200b1e2e-0d13-4a25-881c-1f2ab3d5a820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can read documentation on object types in WordNet, for example by invoking the types:"
      ],
      "metadata": {
        "id": "gPVFTv6lngfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.reader.wordnet.Lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "uLnPl63pnK-M",
        "outputId": "6bf5a869-f1ce-4355-a487-19e7c9f2dcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.wordnet.Lemma"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.corpus.reader.wordnet.Lemma</b><br/>def __init__(wordnet_corpus_reader, synset, name, lexname_index, lex_id, syntactic_marker)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordnet.py</a>The lexical entry for a single morphological form of a\n",
              "sense-disambiguated word.\n",
              "\n",
              "Create a Lemma from a &quot;&lt;word&gt;.&lt;pos&gt;.&lt;number&gt;.&lt;lemma&gt;&quot; string where:\n",
              "&lt;word&gt; is the morphological stem identifying the synset\n",
              "&lt;pos&gt; is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
              "&lt;number&gt; is the sense number, counting from 0.\n",
              "&lt;lemma&gt; is the morphological form of interest\n",
              "\n",
              "Note that &lt;word&gt; and &lt;lemma&gt; can be different, e.g. the Synset\n",
              "&#x27;salt.n.03&#x27; has the Lemmas &#x27;salt.n.03.salt&#x27;, &#x27;salt.n.03.saltiness&#x27; and\n",
              "&#x27;salt.n.03.salinity&#x27;.\n",
              "\n",
              "Lemma attributes, accessible via methods with the same name:\n",
              "\n",
              "- name: The canonical name of this lemma.\n",
              "- synset: The synset that this lemma belongs to.\n",
              "- syntactic_marker: For adjectives, the WordNet string identifying the\n",
              "  syntactic position relative modified noun. See:\n",
              "  https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "  For all other parts of speech, this attribute is None.\n",
              "- count: The frequency of this lemma in wordnet.\n",
              "\n",
              "Lemma methods:\n",
              "\n",
              "Lemmas have the following methods for retrieving related Lemmas. They\n",
              "correspond to the names for the pointer symbols defined here:\n",
              "https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "These methods all return lists of Lemmas:\n",
              "\n",
              "- antonyms\n",
              "- hypernyms, instance_hypernyms\n",
              "- hyponyms, instance_hyponyms\n",
              "- member_holonyms, substance_holonyms, part_holonyms\n",
              "- member_meronyms, substance_meronyms, part_meronyms\n",
              "- topic_domains, region_domains, usage_domains\n",
              "- attributes\n",
              "- derivationally_related_forms\n",
              "- entailments\n",
              "- causes\n",
              "- also_sees\n",
              "- verb_groups\n",
              "- similar_tos\n",
              "- pertainyms</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 219);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.reader.wordnet.Synset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "e5PBoC8invpj",
        "outputId": "dcee5fd5-9825-4c8e-d222-ea3bc975867f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.wordnet.Synset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.corpus.reader.wordnet.Synset</b><br/>def __init__(wordnet_corpus_reader)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordnet.py</a>Create a Synset from a &quot;&lt;lemma&gt;.&lt;pos&gt;.&lt;number&gt;&quot; string where:\n",
              "&lt;lemma&gt; is the word&#x27;s morphological stem\n",
              "&lt;pos&gt; is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
              "&lt;number&gt; is the sense number, counting from 0.\n",
              "\n",
              "Synset attributes, accessible via methods with the same name:\n",
              "\n",
              "- name: The canonical name of this synset, formed using the first lemma\n",
              "  of this synset. Note that this may be different from the name\n",
              "  passed to the constructor if that string used a different lemma to\n",
              "  identify the synset.\n",
              "- pos: The synset&#x27;s part of speech, matching one of the module level\n",
              "  attributes ADJ, ADJ_SAT, ADV, NOUN or VERB.\n",
              "- lemmas: A list of the Lemma objects for this synset.\n",
              "- definition: The definition for this synset.\n",
              "- examples: A list of example strings for this synset.\n",
              "- offset: The offset in the WordNet dict file of this synset.\n",
              "- lexname: The name of the lexicographer file containing this synset.\n",
              "\n",
              "Synset methods:\n",
              "\n",
              "Synsets have the following methods for retrieving related Synsets.\n",
              "They correspond to the names for the pointer symbols defined here:\n",
              "https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "These methods all return lists of Synsets.\n",
              "\n",
              "- hypernyms, instance_hypernyms\n",
              "- hyponyms, instance_hyponyms\n",
              "- member_holonyms, substance_holonyms, part_holonyms\n",
              "- member_meronyms, substance_meronyms, part_meronyms\n",
              "- attributes\n",
              "- entailments\n",
              "- causes\n",
              "- also_sees\n",
              "- verb_groups\n",
              "- similar_tos\n",
              "\n",
              "Additionally, Synsets support the following methods specific to the\n",
              "hypernym relation:\n",
              "\n",
              "- root_hypernyms\n",
              "- common_hypernyms\n",
              "- lowest_common_hypernyms\n",
              "\n",
              "Note that Synsets do not support the following relations because\n",
              "these are defined by WordNet as lexical relations:\n",
              "\n",
              "- antonyms\n",
              "- derivationally_related_forms\n",
              "- pertainyms</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 351);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, retrieve the first lemma corresponding to the adjective _dry_ as `d`:"
      ],
      "metadata": {
        "id": "_nCIbS2Zn7WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d="
      ],
      "metadata": {
        "id": "NRg_XHB6pZf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What lemmas belong to the same SynSet? Retrieve the list."
      ],
      "metadata": {
        "id": "2pxGTK83pagp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here"
      ],
      "metadata": {
        "id": "KN6jSh59phxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the frequency of the lemma `d` recorded in WordNet"
      ],
      "metadata": {
        "id": "e7RATWSxoOp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d.count()"
      ],
      "metadata": {
        "id": "G856bKihm-8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function `ant_freq` that returns the frequency of (the first) antonym of a lemma."
      ],
      "metadata": {
        "id": "TjRKZe5yp6WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ant_freq(x):\n",
        "  #your code here"
      ],
      "metadata": {
        "id": "Ijovshizp7Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply `ant_freq` to `d`. This will output the frequency of _wet_."
      ],
      "metadata": {
        "id": "W63hTqccovBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ant_freq(d)"
      ],
      "metadata": {
        "id": "xbWZj8cqm3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9UHFcCUwO_4"
      },
      "source": [
        "Now, create a dataset that includes for each word in WordNet that has a GloVe vector the lexicographic file (supersense) of its first synset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C43EVE68ytWG"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "wn_words =\n",
        "wn_supersenses ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHXhjXvjyt18"
      },
      "source": [
        "Split the dataset into train and test partitions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lrFM_48yW83"
      },
      "outputs": [],
      "source": [
        "wn_words_train, wn_words_test, wn_supersenses_train, wn_supersenses_test = train_test_split(wn_words,wn_supersenses,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0tWUqkugfe"
      },
      "source": [
        "# 2.4. Logistic regression: word class prediction.\n",
        "\n",
        "Now we can address a classification task. Define a (multinomial) regression model using softmax, choose a loss function and an optimizer for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX3nnLPlu8RZ"
      },
      "outputs": [],
      "source": [
        "num_classes = len(set(wn_supersenses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAF9my4vfpYY"
      },
      "source": [
        "Initialize your model. Use the same Regression class for logistic regression as for linear regression - the difference will come from the objective (loss) function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn7HvScVvazT"
      },
      "outputs": [],
      "source": [
        "logreg_model = Regression(glovedim,num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yxodwdYfzTl"
      },
      "source": [
        "Choose the loss function. This is a crucial choice: some of the loss functions in PyTorch (see https://pytorch.org/docs/stable/nn.html) already include a softmax or a sigmoid in their implementaion, which gives computational advantages. Be sure to read the documentation on your loss function to confirm you made a good choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVRdqxAvvIPC"
      },
      "outputs": [],
      "source": [
        "#your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H-JrZZVfzHF"
      },
      "source": [
        "And initialize the optimiser:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw6Pt_BKvTFx"
      },
      "outputs": [],
      "source": [
        "#your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSNhlheCk4xN"
      },
      "source": [
        "WordNet is quite big. For efficiency, use the following function for splitting your data into batches when processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbA_NKV1k7vX"
      },
      "outputs": [],
      "source": [
        "batch_size = 200\n",
        "def get_batches(src_iter, tgt_iter, batch_size=batch_size):\n",
        "    for batch in more_itertools.chunked(zip(src_iter, tgt_iter), batch_size):\n",
        "        x, y = zip(*batch)\n",
        "        x = torch.stack(x)\n",
        "        y = torch.stack(y)\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2bMjQiKy04C"
      },
      "source": [
        "Train and test your logistic regression model, printing the train and test loss and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpbabReyy3Gg"
      },
      "outputs": [],
      "source": [
        "#your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDWmbmFEh8em"
      },
      "source": [
        "Define a mapping from indices to lexicographic file names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQFoIsxHgExM"
      },
      "outputs": [],
      "source": [
        "#your code\n",
        "itolexname="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the name of lexicographic file 2?"
      ],
      "metadata": {
        "id": "luIUK79GYVzH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zriTsMNl-8PC"
      },
      "outputs": [],
      "source": [
        "itolexname[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eJ39Ocgik1Z"
      },
      "source": [
        "Which supersense (lexicographic file) does your classifier assign to the noun _abstractness_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1JuvmYvgMyk"
      },
      "outputs": [],
      "source": [
        "def predicted_lexname(wd):\n",
        "#your code\n",
        "#\n",
        "\n",
        "predicted_lexname(\"abstractness\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRijRCGLiTyb"
      },
      "source": [
        "Which supersense (lexicographic file) does your classifier assign to the noun _dog_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgePacYfgezw"
      },
      "outputs": [],
      "source": [
        "predicted_lexname(\"dog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL8uxCpyzah1"
      },
      "source": [
        "# 2.5. Hypernymy classification\n",
        "\n",
        "Now, download a lexical entailment (hypernymy) dataset called WBLESS. The dataset was developed by Weeds et al. with the goal of testing models on distinguishing hypernyms from other related word pairs.\n",
        "\n",
        "Weeds et al. (2014) Julie Weeds, Daoud Clarke, Jeremy Reffin, David Weir, and Bill Keller. 2014. Learning to distinguish hypernyms and co-hyponyms. In Proceedings of the 2014 International Conference on Computational Linguistics, pages 2249â€“2259, Dublin, Ireland.\n",
        "\n",
        "WBLESS (together with other relevant datasets) can be conveniently downloaded from the Facebook Research github page by Stephen Roller who worked on hypernymy learning:\n",
        "\n",
        "Stephen Roller, Douwe Kiela, and Maximilian Nickel. 2018. Hearst Patterns Revisited: Automatic Hypernym Detection from Large Text Corpora. ACL.\n",
        "\n",
        "Download the tab-separated dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC37FAiq0TN3"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/facebookresearch/hypernymysuite/raw/main/data/wbless.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqCX7YDt27Vs"
      },
      "source": [
        "Check how the data looks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfLFN1110Zuc"
      },
      "outputs": [],
      "source": [
        "!head wbless.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8H2DTxmi45e"
      },
      "source": [
        "We used ```csv``` above to process a tab separated file. It can also be done using ```pandas```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcKADH0wT-dJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "76613e8f-8355-4d92-c47a-6136ee661d90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     word1    word2  label relation fold\n",
              "0  frigate    craft   True    hyper  val\n",
              "1  trouble     carp  False    other  val\n",
              "2      fox    mouth  False    other  val\n",
              "3     foot    robin  False    other  val\n",
              "4     vest  garment   True    hyper  val"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71b2d0f6-17ff-49f1-8b00-4d9459f070fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word1</th>\n",
              "      <th>word2</th>\n",
              "      <th>label</th>\n",
              "      <th>relation</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frigate</td>\n",
              "      <td>craft</td>\n",
              "      <td>True</td>\n",
              "      <td>hyper</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble</td>\n",
              "      <td>carp</td>\n",
              "      <td>False</td>\n",
              "      <td>other</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fox</td>\n",
              "      <td>mouth</td>\n",
              "      <td>False</td>\n",
              "      <td>other</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>foot</td>\n",
              "      <td>robin</td>\n",
              "      <td>False</td>\n",
              "      <td>other</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vest</td>\n",
              "      <td>garment</td>\n",
              "      <td>True</td>\n",
              "      <td>hyper</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b2d0f6-17ff-49f1-8b00-4d9459f070fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71b2d0f6-17ff-49f1-8b00-4d9459f070fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71b2d0f6-17ff-49f1-8b00-4d9459f070fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f428f6c-ac48-4d3e-8113-44d8ac422440\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f428f6c-ac48-4d3e-8113-44d8ac422440')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f428f6c-ac48-4d3e-8113-44d8ac422440 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "wbless_df",
              "summary": "{\n  \"name\": \"wbless_df\",\n  \"rows\": 1668,\n  \"fields\": [\n    {\n      \"column\": \"word1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 441,\n        \"samples\": [\n          \"cranberry\",\n          \"gill\",\n          \"vertebrate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"club\",\n          \"ambulance\",\n          \"runner-up\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"other\",\n          \"hyper\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"test\",\n          \"val\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "wbless_df = pd.read_csv('wbless.tsv', sep='\\t')\n",
        "wbless_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78WU2dWP3GvT"
      },
      "source": [
        "Now create training and test data for relation classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kP1WKoj3HN2"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkUxGPQN2ODk"
      },
      "source": [
        "Split into training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5TADig-3VZ_"
      },
      "outputs": [],
      "source": [
        "wbless_words_train, wbless_words_test, hypernymy_train, hypernymy_test = train_test_split(wbless_words,hypernymy,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZNxIFOc3kN9"
      },
      "source": [
        "Finally, create, train and test a logistic regression model that predicts whether two words stand in the hypernymy relation given their GloVe vectors.\n",
        "\n",
        "Make sure your model predicts a single score used for the binary decision (hypernymy vs. non-hypernymy) rather than scores for multiple classes, and choose the loss function in pyTorch accordingly.\n",
        "\n",
        "Print the train and test loss and accuracy. Use the concatenation of the two words' vectors as input to the logistic regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkYFJcWH320c"
      },
      "outputs": [],
      "source": [
        "#your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYuoCyuWm-NF"
      },
      "source": [
        "What label does your model predict for the pair _dog,animal_? Your code below should produce a Boolean value, `True` for the positive class (hypernymy) and `False` for the negative class (not hypernymy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Kujrk1QjIJs"
      },
      "outputs": [],
      "source": [
        "def predicted_hypernymy(w1,w2):\n",
        "  #complete the code\n",
        "\n",
        "predicted_hypernymy(\"dog\",\"animal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gR6R_6LnL05"
      },
      "source": [
        "What label does your model predict for the pair _dog,cat_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n40gWmRjuf6"
      },
      "outputs": [],
      "source": [
        "predicted_hypernymy(\"dog\",\"cat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCKBTiCCnRRu"
      },
      "source": [
        "What label does your model predict for the pair _animal,dog_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_9JK2EnnT2d"
      },
      "outputs": [],
      "source": [
        "predicted_hypernymy(\"animal\",\"dog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.6 Using FrameNet\n",
        "\n"
      ],
      "metadata": {
        "id": "-xR2nXnH5HJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can explore FrameNet online:\n",
        "https://framenet.icsi.berkeley.edu/frameIndex\n",
        "\n",
        "Or read detailed documentation here:\n",
        "https://framenet2.icsi.berkeley.edu/docs/r1.7/book.pdf\n",
        "\n",
        "Now, load FrameNet via the NLTK package:"
      ],
      "metadata": {
        "id": "nENYVvXQiwMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('framenet_v17')\n",
        "from nltk.corpus import framenet as fn"
      ],
      "metadata": {
        "id": "K1kaoStljcY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fn.lus` allows to retrieve lexical units (LUs) recorded in FrameNet. A lexical unit approximately corresponds to a lemma in WordNet, i.e. a word taken in a specific sense. Without additional parameters, it returns a complete list:\n",
        "\n"
      ],
      "metadata": {
        "id": "K7PE47iCaR2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijewRC_JaShn",
        "outputId": "fc97de4d-772e-4a3d-d7bc-364658083c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<lu ID=16601 name=(can't) help.v>, <lu ID=14632 name=(in/out of) line.n>, ...]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also retrieve lexical units by regular expression search. For example, the following returns the list of LUs that contain string _pres_ at the beginning of the LU name:"
      ],
      "metadata": {
        "id": "SC2XBdpyauNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lus('^pres')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJCGq6a181-y",
        "outputId": "bd226881-6ed9-45d0-8897-2850eb7a540e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<lu ID=957 name=press.v>, <lu ID=10117 name=press.v>, ...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Individual lexical units can be retrieved by ID, for example:"
      ],
      "metadata": {
        "id": "aKfBkMyPbbLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUpopayw9AFe",
        "outputId": "2b74acb7-d6e2-4132-c341-fb3b9330bda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lexical unit (10117): press.v\n",
              "\n",
              "[definition]\n",
              "  COD: make strong efforts to persuade or force to do something.\n",
              "\n",
              "[frame] Attempt_suasion(87)\n",
              "\n",
              "[POS] V\n",
              "\n",
              "[status] Finished_Initial\n",
              "\n",
              "[lexemes] press/V\n",
              "\n",
              "[semTypes] 0 semantic types\n",
              "\n",
              "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu10117.xml\n",
              "\n",
              "[subCorpus] 12 subcorpora\n",
              "  01-T-Won-(1), 02-T-Wto-(1), 03-T-Winto-(1), 04-T-Wwith-(1),\n",
              "  05-T-Wfor-(1), 06-AVP-T-(1), 07-T-AVP-(1), 08-T-NP-PP-(1),\n",
              "  09-T-NP-(1), manually-added, other-matched-(1), other-\n",
              "  unmatched-(1)\n",
              "\n",
              "[exemplars] 20 sentences across all subcorpora"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terms that show up in square brackets are attributes, in this case of the lexical unit. They include usage examples:"
      ],
      "metadata": {
        "id": "9QHkZL7Xb2me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117).exemplars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzDT4Cuob5Ku",
        "outputId": "70490aec-6000-4c17-e330-a9004c306b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "exemplar sentences for press.v in Attempt_suasion:\n",
              "\n",
              "[0] The sponsors of the bill made clear their intention to press for a vote on it within the current legislative session .\n",
              "[1] Anne McIntosh , MEP for North East Essex , is pressing the Government to reverse its policy of controlled retreat , which allows the sea to gradually take its natural course .\n",
              "[2] Lewis pressed Adam to accompany him on those solicitous weekend visits but Adam nearly always said he was too busy or would be bored .\n",
              "[3] The committee also agreed to press for changes to the rule which limits the level of right-to-buy discounts in the case of newly built houses or those recently modernised .\n",
              "[4] It is no secret that Damascus has been using the PKK as a bargaining chip to press Turkey into complying with its demands for more water from the Euphrates , on which it heavily depends .\n",
              "[5] The tenant 's adviser should therefore press for an obligation on the landlord to notify the tenant of any application made by him to the President .\n",
              "[6] They press for much needed democratic reforms to enable the citizens to participate .\n",
              "[7] When I press him for more names he suddenly gets the deer-caught-in-the-headlights look , and , deciding he 's already revealed too much , replies , ` Ah , just people . \"\n",
              "[8] In these circumstances the Soviet Union has pressed more recently for a more limited regime for the Gulf involving restrictions on the naval presence of the Great Powers in the region .\n",
              "[9] Mr Gorbachev may refrain from saying it publicly on Saturday but he can be expected to press Mr Honecker all the more urgently in private .\n",
              "[10] The houses of Hohenstaufen ( Ghibellines ) and Welf ( Guelphs ) both pressed their claims to the royal crown but as already described , Frederick Barbarossa succeeded in his claim .\n",
              "[11] BRITISH Petroleum is to press Chancellor Norman Lamont for a reduction in North Sea taxes and is making additional cuts in capital spending to avoid the risks of further cash and dividend pressures .\n",
              "[12] We will press them to put into practice the principles of the Maastricht declaration .\n",
              "[13] Once in office Healey pressed his Nato colleagues to accept that no conflict was possible in Europe at any level between that of a local skirmish and all-out war .\n",
              "[14] Suppose she was pressing him to pay it back because she needed it for her vineyard . \"\n",
              "[15] I would n't press you for a decision , I promise you .\n",
              "[16] We will press for similar standards throughout the European Community and strengthen the work of consumer groups and advice centres so that the aspirations and standards are met .\n",
              "[17] Senior Tories pressed Michael Heseltine , the environment secretary , to discuss radical changes to the poll tax .\n",
              "[18] With membership of the Church of England steadily dwindling , strong-willed vicars are pressing equally strong-willed and often non-religious ringers to attend services .\n",
              "[19] QN : Did Sharon urge the US leader to keep pressing Iran to give up its nuclear program altogether ?\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and the frame that the lexical unit evokes, which in turn has its own attributes:"
      ],
      "metadata": {
        "id": "ef8vlLl_ckrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117).frame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKLSgeEbqi6",
        "outputId": "c4d72ac8-8231-4c84-f042-67199f30751b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "frame (87): Attempt_suasion\n",
              "\n",
              "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Attempt_suasion.xml\n",
              "\n",
              "[definition]\n",
              "  The  Speaker expresses through language his wish to get the\n",
              "  Addressee to act in some way that will help to bring about events\n",
              "  or states described in the Content. There is no implication that\n",
              "  the Addressee forms an intention to act, let alone acts.     'Mr\n",
              "  Smithers always encourages the employees to stay late and work\n",
              "  harder.'  'Dennis Rodman advises moderation in all things. INI'\n",
              "  The Content most prototypically refers to an action that the\n",
              "  Addressee will carry out themselves, but may (in the case of\n",
              "  valences with a non-finite Content clause) merely refer to a\n",
              "  situation that they have indirect influence over, as in the\n",
              "  following  'When I talked to her, I suggested that he be removed\n",
              "  from office . DNI '\n",
              "\n",
              "[semTypes] 0 semantic types\n",
              "\n",
              "[frameRelations] 8 frame relations\n",
              "  <Parent=Attempt -- Inheritance -> Child=Attempt_suasion>\n",
              "  <Parent=Attempt_suasion -- Using -> Child=Suasion>\n",
              "  <Parent=Communication -- Using -> Child=Attempt_suasion>\n",
              "  <Parent=Subjective_influence -- Using -> Child=Attempt_suasion>\n",
              "  <Source=Attempt_suasion -- ReFraming_Mapping -> Target=Causation>\n",
              "  <Source=Attempt_suasion -- ReFraming_Mapping -> Target=Manipulate_into_doing>\n",
              "  <Source=Attempt_suasion -- ReFraming_Mapping -> Target=Subjective_influence>\n",
              "  <Source=Request -- ReFraming_Mapping -> Target=Attempt_suasion>\n",
              "\n",
              "[lexUnit] 16 lexical units\n",
              "  admonish.v (1809), advise.v (1810), advocate.v (13475), beg.v\n",
              "  (1812), cajole.v (1813), enjoin.v (18519), exhort.v (1818),\n",
              "  lobby.v (13116), press.v (10117), pressure.n (11455), pressure.v\n",
              "  (1820), prevail.v (1821), recommend.v (16934), suggest.v (16340),\n",
              "  suggestion.n (18450), urge.v (1805)\n",
              "\n",
              "\n",
              "[FE] 20 frame elements\n",
              "            Core: Addressee (409), Content (408), Medium (427), Salient_entity (14440), Speaker (410), Topic (414)\n",
              "      Peripheral: Degree (1225), Manner (1222), Means (1224), Place (12626), Purpose (13346), Time (10234)\n",
              "  Extra-Thematic: Circumstances (10237), Depictive (1223), Explanation (10235), Frequency (10511), Group (10508), Period_of_iterations (10236), Re-encoding (10513), Role (15518)\n",
              "\n",
              "[FEcoreSets] 2 frame element core sets\n",
              "  Content, Topic\n",
              "  Speaker, Medium"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Find all LUs on FrameNet that share the frame with the noun *car*. Print these words along with their definitions."
      ],
      "metadata": {
        "id": "Cctg8so28msu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here"
      ],
      "metadata": {
        "id": "JiVFBhPqjgFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Define a function that takes a FrameNet frame as input and prints out the definitions of all core frame elements associated with the frame. For example for the frame associated with the noun _car_ your function will print the definition of the only core frame element _Vehicle_:\n",
        "\n",
        "\n",
        "> Vehicle is the transportation device that the human beings use to travel.This FE is incorporated into each LU in this frame."
      ],
      "metadata": {
        "id": "Y1yrjnlDlBsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printcoreFE(frame):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    frame: a frame object from FrameNet\n",
        "  \"\"\"\n",
        "#your code here"
      ],
      "metadata": {
        "id": "jmbJCfVslFQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test your function on the frame evoked by the verb _sing_:"
      ],
      "metadata": {
        "id": "FzBOh16LlNrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sing=\n",
        "printcoreFE(sing)"
      ],
      "metadata": {
        "id": "s0I2ZfltlOTy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}